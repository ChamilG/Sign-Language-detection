{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-14T05:23:35.237744Z","iopub.execute_input":"2023-08-14T05:23:35.238127Z","iopub.status.idle":"2023-08-14T05:23:35.270326Z","shell.execute_reply.started":"2023-08-14T05:23:35.238096Z","shell.execute_reply":"2023-08-14T05:23:35.269446Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"/kaggle/input/sign-language-mnist/sign_mnist_test.csv\n/kaggle/input/sign-language-mnist/amer_sign2.png\n/kaggle/input/sign-language-mnist/amer_sign3.png\n/kaggle/input/sign-language-mnist/sign_mnist_train.csv\n/kaggle/input/sign-language-mnist/american_sign_language.PNG\n/kaggle/input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv\n/kaggle/input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:23:35.298531Z","iopub.execute_input":"2023-08-14T05:23:35.299174Z","iopub.status.idle":"2023-08-14T05:23:35.306829Z","shell.execute_reply.started":"2023-08-14T05:23:35.299135Z","shell.execute_reply":"2023-08-14T05:23:35.305453Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/sign-language-mnist/sign_mnist_train.csv')\ntest_df = pd.read_csv('/kaggle/input/sign-language-mnist/sign_mnist_test.csv')\ntrain_dataset.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:23:35.309751Z","iopub.execute_input":"2023-08-14T05:23:35.310627Z","iopub.status.idle":"2023-08-14T05:23:38.478414Z","shell.execute_reply.started":"2023-08-14T05:23:35.310577Z","shell.execute_reply":"2023-08-14T05:23:38.477306Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0      3     107     118     127     134     139     143     146     150   \n1      6     155     157     156     156     156     157     156     158   \n2      2     187     188     188     187     187     186     187     188   \n3      2     211     211     212     212     211     210     211     210   \n4     13     164     167     170     172     176     179     180     184   \n5     16     161     168     172     173     178     184     189     193   \n6      8     134     134     135     135     136     137     137     138   \n7     22     114      42      74      99     104     109     117     127   \n8      3     169     174     176     180     183     185     187     188   \n9      3     189     189     189     190     190     191     190     190   \n\n   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n0     153  ...       207       207       207       207       206       206   \n1     158  ...        69       149       128        87        94       163   \n2     187  ...       202       201       200       199       198       199   \n3     210  ...       235       234       233       231       230       226   \n4     185  ...        92       105       105       108       133       163   \n5     196  ...        76        74        68        62        53        55   \n6     138  ...       109       102        91        65       138       189   \n7     142  ...       214       218       220       223       223       225   \n8     190  ...       119       118       123       120       118       114   \n9     190  ...        13        53       200       204       201       201   \n\n   pixel781  pixel782  pixel783  pixel784  \n0       206       204       203       202  \n1       175       103       135       149  \n2       198       195       194       195  \n3       225       222       229       163  \n4       157       163       164       179  \n5        48       238       255       255  \n6       179       181       181       179  \n7       227       227       228       228  \n8        94        74        61        57  \n9       193       175       178       156  \n\n[10 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>107</td>\n      <td>118</td>\n      <td>127</td>\n      <td>134</td>\n      <td>139</td>\n      <td>143</td>\n      <td>146</td>\n      <td>150</td>\n      <td>153</td>\n      <td>...</td>\n      <td>207</td>\n      <td>207</td>\n      <td>207</td>\n      <td>207</td>\n      <td>206</td>\n      <td>206</td>\n      <td>206</td>\n      <td>204</td>\n      <td>203</td>\n      <td>202</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>155</td>\n      <td>157</td>\n      <td>156</td>\n      <td>156</td>\n      <td>156</td>\n      <td>157</td>\n      <td>156</td>\n      <td>158</td>\n      <td>158</td>\n      <td>...</td>\n      <td>69</td>\n      <td>149</td>\n      <td>128</td>\n      <td>87</td>\n      <td>94</td>\n      <td>163</td>\n      <td>175</td>\n      <td>103</td>\n      <td>135</td>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>187</td>\n      <td>188</td>\n      <td>188</td>\n      <td>187</td>\n      <td>187</td>\n      <td>186</td>\n      <td>187</td>\n      <td>188</td>\n      <td>187</td>\n      <td>...</td>\n      <td>202</td>\n      <td>201</td>\n      <td>200</td>\n      <td>199</td>\n      <td>198</td>\n      <td>199</td>\n      <td>198</td>\n      <td>195</td>\n      <td>194</td>\n      <td>195</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>211</td>\n      <td>211</td>\n      <td>212</td>\n      <td>212</td>\n      <td>211</td>\n      <td>210</td>\n      <td>211</td>\n      <td>210</td>\n      <td>210</td>\n      <td>...</td>\n      <td>235</td>\n      <td>234</td>\n      <td>233</td>\n      <td>231</td>\n      <td>230</td>\n      <td>226</td>\n      <td>225</td>\n      <td>222</td>\n      <td>229</td>\n      <td>163</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13</td>\n      <td>164</td>\n      <td>167</td>\n      <td>170</td>\n      <td>172</td>\n      <td>176</td>\n      <td>179</td>\n      <td>180</td>\n      <td>184</td>\n      <td>185</td>\n      <td>...</td>\n      <td>92</td>\n      <td>105</td>\n      <td>105</td>\n      <td>108</td>\n      <td>133</td>\n      <td>163</td>\n      <td>157</td>\n      <td>163</td>\n      <td>164</td>\n      <td>179</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>16</td>\n      <td>161</td>\n      <td>168</td>\n      <td>172</td>\n      <td>173</td>\n      <td>178</td>\n      <td>184</td>\n      <td>189</td>\n      <td>193</td>\n      <td>196</td>\n      <td>...</td>\n      <td>76</td>\n      <td>74</td>\n      <td>68</td>\n      <td>62</td>\n      <td>53</td>\n      <td>55</td>\n      <td>48</td>\n      <td>238</td>\n      <td>255</td>\n      <td>255</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>8</td>\n      <td>134</td>\n      <td>134</td>\n      <td>135</td>\n      <td>135</td>\n      <td>136</td>\n      <td>137</td>\n      <td>137</td>\n      <td>138</td>\n      <td>138</td>\n      <td>...</td>\n      <td>109</td>\n      <td>102</td>\n      <td>91</td>\n      <td>65</td>\n      <td>138</td>\n      <td>189</td>\n      <td>179</td>\n      <td>181</td>\n      <td>181</td>\n      <td>179</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>22</td>\n      <td>114</td>\n      <td>42</td>\n      <td>74</td>\n      <td>99</td>\n      <td>104</td>\n      <td>109</td>\n      <td>117</td>\n      <td>127</td>\n      <td>142</td>\n      <td>...</td>\n      <td>214</td>\n      <td>218</td>\n      <td>220</td>\n      <td>223</td>\n      <td>223</td>\n      <td>225</td>\n      <td>227</td>\n      <td>227</td>\n      <td>228</td>\n      <td>228</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3</td>\n      <td>169</td>\n      <td>174</td>\n      <td>176</td>\n      <td>180</td>\n      <td>183</td>\n      <td>185</td>\n      <td>187</td>\n      <td>188</td>\n      <td>190</td>\n      <td>...</td>\n      <td>119</td>\n      <td>118</td>\n      <td>123</td>\n      <td>120</td>\n      <td>118</td>\n      <td>114</td>\n      <td>94</td>\n      <td>74</td>\n      <td>61</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3</td>\n      <td>189</td>\n      <td>189</td>\n      <td>189</td>\n      <td>190</td>\n      <td>190</td>\n      <td>191</td>\n      <td>190</td>\n      <td>190</td>\n      <td>190</td>\n      <td>...</td>\n      <td>13</td>\n      <td>53</td>\n      <td>200</td>\n      <td>204</td>\n      <td>201</td>\n      <td>201</td>\n      <td>193</td>\n      <td>175</td>\n      <td>178</td>\n      <td>156</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 785 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y_train = train_df['label']\ny_test = test_df['label']\ndel train_df['label']\ndel test_df['label']","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:23:38.479782Z","iopub.execute_input":"2023-08-14T05:23:38.480112Z","iopub.status.idle":"2023-08-14T05:23:38.490175Z","shell.execute_reply.started":"2023-08-14T05:23:38.480082Z","shell.execute_reply":"2023-08-14T05:23:38.489027Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"label binarizer will convert all the categorical labels(which are the numbers of the letters in the alphabet) in to binary which makes the machine learning process more fast","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\nlabel_binarizer = LabelBinarizer()\ny_train = label_binarizer.fit_transform(y_train)\ny_test = label_binarizer.fit_transform(y_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:23:38.492792Z","iopub.execute_input":"2023-08-14T05:23:38.493350Z","iopub.status.idle":"2023-08-14T05:23:38.519467Z","shell.execute_reply.started":"2023-08-14T05:23:38.493302Z","shell.execute_reply":"2023-08-14T05:23:38.518523Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"normalization is done to make sure the training process happens smoothly","metadata":{}},{"cell_type":"code","source":"x_train = train_df.values\nx_test = test_df.values\n\n# normalization\nx_train = x_train/255\nx_test = x_test/255","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:23:38.520617Z","iopub.execute_input":"2023-08-14T05:23:38.520916Z","iopub.status.idle":"2023-08-14T05:23:38.808830Z","shell.execute_reply.started":"2023-08-14T05:23:38.520888Z","shell.execute_reply":"2023-08-14T05:23:38.807661Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"next code is for reshaping the input data arrays \n-1: The -1 is used to automatically calculate the size of this dimension based on the total number of elements and the other dimensions specified. It essentially means \"whatever size is needed to maintain the total number of elements\".\n28, 28: These two dimensions are specified to create a 2D grid that corresponds to the image dimensions. Each image is expected to be 28x28 pixels.\n1: The last dimension with size 1 indicates that the images are grayscale. If the images were RGB color images, this value would be 3 (for the red, green, and blue channels).","metadata":{}},{"cell_type":"code","source":"x_train = x_train.reshape(-1, 28, 28, 1)\nx_test = x_test.reshape(-1, 28, 28, 1)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:23:38.810560Z","iopub.execute_input":"2023-08-14T05:23:38.811048Z","iopub.status.idle":"2023-08-14T05:23:38.816859Z","shell.execute_reply.started":"2023-08-14T05:23:38.811007Z","shell.execute_reply":"2023-08-14T05:23:38.815653Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"The next step is to create the data generator to randomly implement changes to the data, increasing the amount of training examples and making the images more realistic by adding noise and transformations to different instances.","metadata":{}},{"cell_type":"markdown","source":"Datagenerator = In image classification, a data generator is a utility that dynamically generates batches of augmented or preprocessed image data for training machine learning models, particularly deep learning models. It's a crucial component when dealing with large datasets, as it enables efficient memory usage and allows for data augmentation during training, which can improve the model's generalization and performance.","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,\n        samplewise_center=False, \n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        rotation_range=10,\n        zoom_range = 0.1, \n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        horizontal_flip=False,\n        vertical_flip=False)\n\ndatagen.fit(x_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:23:38.818158Z","iopub.execute_input":"2023-08-14T05:23:38.818514Z","iopub.status.idle":"2023-08-14T05:23:38.905713Z","shell.execute_reply.started":"2023-08-14T05:23:38.818486Z","shell.execute_reply":"2023-08-14T05:23:38.904556Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"The Sequential model in Keras (or tf.keras when using TensorFlow 2) is a linear stack of layers that is used to build neural networks. It provides a straightforward and intuitive way to create feedforward architectures, where the data flows sequentially through each layer, from input to output.\n\n* You build the architecture of the neural network by **adding layers** to the model using the .add() method. You can add various types of layers, such as convolutional layers, dense (fully connected) layers, activation layers, dropout layers, and more.","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Flatten())\nmodel.add(Dense(units = 512 , activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(units = 24 , activation = 'softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:23:38.907428Z","iopub.execute_input":"2023-08-14T05:23:38.908586Z","iopub.status.idle":"2023-08-14T05:23:39.091533Z","shell.execute_reply.started":"2023-08-14T05:23:38.908538Z","shell.execute_reply":"2023-08-14T05:23:39.090036Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\nmodel.summary()\n\nhistory = model.fit(datagen.flow(x_train,y_train, batch_size = 128) ,epochs = 20 , validation_data = (x_test, y_test))\n\nmodel.save('smnist.h5')","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:23:39.093975Z","iopub.execute_input":"2023-08-14T05:23:39.094544Z","iopub.status.idle":"2023-08-14T05:46:09.123739Z","shell.execute_reply.started":"2023-08-14T05:23:39.094511Z","shell.execute_reply":"2023-08-14T05:46:09.122622Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_3 (Conv2D)           (None, 28, 28, 75)        750       \n                                                                 \n batch_normalization_3 (Batc  (None, 28, 28, 75)       300       \n hNormalization)                                                 \n                                                                 \n max_pooling2d_3 (MaxPooling  (None, 14, 14, 75)       0         \n 2D)                                                             \n                                                                 \n conv2d_4 (Conv2D)           (None, 14, 14, 50)        33800     \n                                                                 \n dropout_2 (Dropout)         (None, 14, 14, 50)        0         \n                                                                 \n batch_normalization_4 (Batc  (None, 14, 14, 50)       200       \n hNormalization)                                                 \n                                                                 \n max_pooling2d_4 (MaxPooling  (None, 7, 7, 50)         0         \n 2D)                                                             \n                                                                 \n conv2d_5 (Conv2D)           (None, 7, 7, 25)          11275     \n                                                                 \n batch_normalization_5 (Batc  (None, 7, 7, 25)         100       \n hNormalization)                                                 \n                                                                 \n max_pooling2d_5 (MaxPooling  (None, 4, 4, 25)         0         \n 2D)                                                             \n                                                                 \n flatten_1 (Flatten)         (None, 400)               0         \n                                                                 \n dense_2 (Dense)             (None, 512)               205312    \n                                                                 \n dropout_3 (Dropout)         (None, 512)               0         \n                                                                 \n dense_3 (Dense)             (None, 24)                12312     \n                                                                 \n=================================================================\nTotal params: 264,049\nTrainable params: 263,749\nNon-trainable params: 300\n_________________________________________________________________\nEpoch 1/20\n215/215 [==============================] - 58s 261ms/step - loss: 1.0146 - accuracy: 0.6802 - val_loss: 3.6334 - val_accuracy: 0.0608\nEpoch 2/20\n215/215 [==============================] - 57s 263ms/step - loss: 0.2097 - accuracy: 0.9318 - val_loss: 1.2739 - val_accuracy: 0.5731\nEpoch 3/20\n215/215 [==============================] - 56s 258ms/step - loss: 0.0950 - accuracy: 0.9699 - val_loss: 0.2863 - val_accuracy: 0.9034\nEpoch 4/20\n215/215 [==============================] - 56s 261ms/step - loss: 0.0581 - accuracy: 0.9822 - val_loss: 0.0387 - val_accuracy: 0.9890\nEpoch 5/20\n215/215 [==============================] - 55s 255ms/step - loss: 0.0461 - accuracy: 0.9852 - val_loss: 0.1902 - val_accuracy: 0.9237\nEpoch 6/20\n215/215 [==============================] - 56s 259ms/step - loss: 0.0401 - accuracy: 0.9871 - val_loss: 0.0958 - val_accuracy: 0.9649\nEpoch 7/20\n215/215 [==============================] - 56s 259ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.0330 - val_accuracy: 0.9848\nEpoch 8/20\n215/215 [==============================] - 55s 256ms/step - loss: 0.0243 - accuracy: 0.9928 - val_loss: 0.0616 - val_accuracy: 0.9743\nEpoch 9/20\n215/215 [==============================] - 55s 254ms/step - loss: 0.0268 - accuracy: 0.9913 - val_loss: 0.0250 - val_accuracy: 0.9916\nEpoch 10/20\n215/215 [==============================] - 55s 256ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.0347 - val_accuracy: 0.9901\nEpoch 11/20\n215/215 [==============================] - 54s 253ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.1108 - val_accuracy: 0.9629\nEpoch 12/20\n215/215 [==============================] - 54s 250ms/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 0.0670 - val_accuracy: 0.9717\nEpoch 13/20\n215/215 [==============================] - 57s 267ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.0410 - val_accuracy: 0.9877\nEpoch 14/20\n215/215 [==============================] - 53s 248ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0403 - val_accuracy: 0.9859\nEpoch 15/20\n215/215 [==============================] - 57s 265ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.0045 - val_accuracy: 0.9989\nEpoch 16/20\n215/215 [==============================] - 55s 256ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.0694 - val_accuracy: 0.9774\nEpoch 17/20\n215/215 [==============================] - 55s 257ms/step - loss: 0.0183 - accuracy: 0.9936 - val_loss: 0.0589 - val_accuracy: 0.9805\nEpoch 18/20\n215/215 [==============================] - 57s 266ms/step - loss: 0.0249 - accuracy: 0.9925 - val_loss: 0.0245 - val_accuracy: 0.9891\nEpoch 19/20\n215/215 [==============================] - 55s 254ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.0091 - val_accuracy: 0.9958\nEpoch 20/20\n215/215 [==============================] - 55s 256ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.7336 - val_accuracy: 0.8614\n","output_type":"stream"}]}]}